# 概述

模型正则化：限制参数的大小

模型正则化Regularization

## 岭回归

$$
目标是：使\sum^m_{i=1}(y^{(i)} - \theta_0 - \theta_1X_1^{(i)} - \theta_2X_2^{(i)} - \dotsc - \theta_nX_n^{(i)})^2 尽可能小
\\其实目标：使J(\theta) = MSE(y, \hat{y};\theta) 尽可能小 \\
加入模型正则化，目标：使J(\theta) = MSE(y, \hat{y};\theta) + \alpha\frac{1}{2}\sum^m_{i=1}\theta_i^2 尽可能小，
$$

相当于变相的使 参数都需要尽可能小

## LASSO回归

LASSO Regression

$$
目标：使J(\theta) = MSE(y, \hat{y};\theta) + \alpha\sum^m_{i=1}|\theta_i| 尽可能小，
$$

Least Absolute Shrinkage and Selection Operator Regerssion

lasso趋向于使得一部分theta值变为0，所以可作为特征选择用

## L1正则，L2正则

$$
Lp范数 ||x||_p = (\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}  \\

Ridge: \space \sum^m_{i=1}\theta_i^2 \space L2正则项\\
Lasso: \space \sum^m_{i=1}|\theta_i| \space L1正则项

$$

## L0正则

$$
J(\theta) = MSE(y, \hat{y};\theta) + min\{number-of-non-zero-\theta\} \\
使非0的\theta 个数尽量少
$$

实际用L1取代，因为L0正则的优化是一个NP难得问题

## 弹性网 Elastic Net

$$
J(\theta) = MSE(y, \hat{y};\theta) + r\alpha\frac{1}{2}\sum^m_{i=1}\theta_i^2 + \frac{1-r}{2}\alpha\sum^m_{i=1}|\theta_i|
$$

结合ridge和lasso的优势

通常实施过程一般先做岭回归，